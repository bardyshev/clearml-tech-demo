{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "edyDFX_Ih5-j"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from collections import defaultdict\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "import albumentations as A\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "import torchvision.models as models\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from clearml import Dataset as ClearMLDataset, Logger, OutputModel, Task\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 666\n",
    "IDX2LABEL = {\n",
    "    0: 'n02111500-Great_Pyrenees',\n",
    "    1: 'n02099712-Labrador_retriever',\n",
    "    2: 'n02093754-Border_terrier',\n",
    "    3: 'n02096294-Australian_terrier',\n",
    "    4: 'n02088632-bluetick',\n",
    "    5: 'n02104365-schipperke',\n",
    "    6: 'n02108422-bull_mastiff',\n",
    "    7: 'n02115641-dingo',\n",
    "    8: 'n02108551-Tibetan_mastiff',\n",
    "    9: 'n02096437-Dandie_Dinmont',\n",
    "    10: 'n02108915-French_bulldog',\n",
    "    11: 'n02102177-Welsh_springer_spaniel',\n",
    "    12: 'n02092002-Scottish_deerhound',\n",
    "    13: 'n02099601-golden_retriever',\n",
    "    14: 'n02111277-Newfoundland',\n",
    "    15: 'n02091134-whippet',\n",
    "}\n",
    "LABEL2IDX = {v: k for k, v in IDX2LABEL.items()}\n",
    "NUM_CLASSES = len(IDX2LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9EtOPkNwh5-8"
   },
   "outputs": [],
   "source": [
    "class AnimalsDataset(Dataset):\n",
    "    def __init__(self, images_filepaths, transform=None):\n",
    "        self.images_filepaths = images_filepaths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images_filepaths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_filepath = self.images_filepaths[idx]\n",
    "        image = cv2.imread(image_filepath)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        label = LABEL2IDX[os.path.normpath(image_filepath).split(os.sep)[-2]]\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image=image)[\"image\"]\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_all_files_in_dir(path):\n",
    "    \n",
    "    result = [os.path.join(dp, f) for dp, dn, filenames in os.walk(path) for f in filenames if os.path.splitext(f)[1] == '.jpg']\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paths(data_path):\n",
    "    paths = []\n",
    "    class_labels = []\n",
    "    for label in LABEL2IDX.keys():\n",
    "        label_paths = [os.path.join(label, item) for item in os.listdir(os.path.join(data_path, label))]\n",
    "        paths.extend(label_paths)\n",
    "        class_labels.extend([label] * len(label_paths))\n",
    "    return paths, class_labels\n",
    "\n",
    "\n",
    "def split(paths, class_labels):\n",
    "    train_paths, val_test_paths, _, val_test_labels = train_test_split(paths, class_labels, test_size=0.1,\n",
    "                                                                       random_state=SEED)\n",
    "    val_paths, test_paths, _, _ = train_test_split(val_test_paths, val_test_labels, test_size=0.5, random_state=SEED)\n",
    "    return train_paths, val_paths, test_paths\n",
    "\n",
    "\n",
    "def copy_files(data_path, new_data_path, paths, dataset_name, verbose = False):\n",
    "    for path in tqdm(paths, total=len(paths), desc=f\"Copying {dataset_name} files\", disable=not verbose):\n",
    "        shutil.copy(os.path.join(data_path, path), os.path.join(new_data_path, dataset_name, path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ========"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML Task: created new task id=d0966bbe57c247bc92addb98acf5856b\n",
      "ClearML results page: http://10.72.148.193:8080/projects/cdde80f225cb43d288c9078f180af237/experiments/d0966bbe57c247bc92addb98acf5856b/output/log\n",
      "2022-11-10 18:45:33,122 - clearml.Task - INFO - Storing jupyter notebook directly as code\n",
      "ClearML Monitor: GPU monitoring failed getting GPU reading, switching off GPU monitoring\n"
     ]
    }
   ],
   "source": [
    "task = Task.init(project_name = 'torch demo', task_name = 'train model and log')\n",
    "output_model = OutputModel(task=task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-10 18:46:00,442 - clearml - WARNING - Switching to remote execution, output log page http://10.72.148.193:8080/projects/cdde80f225cb43d288c9078f180af237/experiments/d0966bbe57c247bc92addb98acf5856b/output/log\n"
     ]
    }
   ],
   "source": [
    "task.set_base_docker(docker_image='python:3.9', docker_arguments='--env http_proxy=http://sa0000mtsaimlplat:p%25G%21621AP%2BdbjH0@bproxy.pv.mts.ru:3128 --env https_proxy=http://sa0000mtsaimlplat:p%25G%21621AP%2BdbjH0@bproxy.pv.mts.ru:3128 --env no_proxy=localhost,127.0.0.1,localaddress,localdomain.com,10.72.148.193')\n",
    "task.execute_remotely(queue_name='ai-gpu-docker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = ClearMLDataset.get(dataset_name='animal-data')\n",
    "local_copy = raw_data.get_local_copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths, class_labels = get_paths(local_copy)\n",
    "train_paths, val_paths, test_paths = split(paths, class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = True\n",
    "\n",
    "dataset_folder = 'dataset_split/'\n",
    "os.makedirs(dataset_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_name in [\"train\", \"test\", \"val\"]:\n",
    "    for label in LABEL2IDX.keys():\n",
    "        os.makedirs(os.path.join(dataset_folder, dataset_name, label), exist_ok=True)\n",
    "        \n",
    "for ds_paths, dataset_name in zip([train_paths, val_paths, test_paths], [\"train\", \"val\", \"test\"]):\n",
    "    copy_files(local_copy, dataset_folder, ds_paths, dataset_name, verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_path = return_all_files_in_dir(os.path.join(dataset_folder, 'train/'))\n",
    "val_images_path = return_all_files_in_dir(os.path.join(dataset_folder, 'val/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mm_NP-c4h5-_"
   },
   "outputs": [],
   "source": [
    "train_transform = A.Compose(\n",
    "    [\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.GaussNoise(p=0.2),\n",
    "        A.RandomBrightnessContrast(p=0.3),\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        A.Resize(224, 224),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")\n",
    "train_dataset = AnimalsDataset(images_filepaths=train_images_path, transform=train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RKin1XAwh5_B"
   },
   "outputs": [],
   "source": [
    "val_transform = A.Compose(\n",
    "    [\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        A.Resize(224, 224),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")\n",
    "val_dataset = AnimalsDataset(images_filepaths=val_images_path, transform=val_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bgTqE0eYSjDh"
   },
   "outputs": [],
   "source": [
    "def calculate_accuracy(output, target):\n",
    "    probs = torch.softmax(output, dim=1)\n",
    "    classes = probs.argmax(dim=1)\n",
    "    \n",
    "    return torch.true_divide((target == classes).sum(dim=0), target.size(0)).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zRhPJiCch5_D"
   },
   "outputs": [],
   "source": [
    "class MetricMonitor:\n",
    "    def __init__(self, float_precision=3):\n",
    "        self.float_precision = float_precision\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.metrics = defaultdict(lambda: {\"val\": 0, \"count\": 0, \"avg\": 0})\n",
    "\n",
    "    def update(self, metric_name, val):\n",
    "        metric = self.metrics[metric_name]\n",
    "\n",
    "        metric[\"val\"] += val\n",
    "        metric[\"count\"] += 1\n",
    "        metric[\"avg\"] = metric[\"val\"] / metric[\"count\"]\n",
    "        \n",
    "    def get(self, metric_name):\n",
    "        return \n",
    "\n",
    "    def __str__(self):\n",
    "        return \" | \".join(\n",
    "            [\n",
    "                \"{metric_name}: {avg:.{float_precision}f}\".format(\n",
    "                    metric_name=metric_name, avg=metric[\"avg\"], float_precision=self.float_precision\n",
    "                )\n",
    "                for (metric_name, metric) in self.metrics.items()\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uOJZEhwSh5_G"
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"model\": \"resnet18\",\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \"lr\": 0.001,\n",
    "    \"batch_size\": 128,\n",
    "    \"num_workers\": 0,\n",
    "    \"epochs\": 3,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task.connect(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W7HipbJ8h5_I"
   },
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=False)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, NUM_CLASSES)\n",
    "model = model.to(params[\"device\"])\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().to(params[\"device\"])\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=params[\"lr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DANylNevh5_N"
   },
   "outputs": [],
   "source": [
    "train_data_loader = DataLoader(\n",
    "    train_dataset, batch_size=params[\"batch_size\"], shuffle=True, num_workers=params[\"num_workers\"], pin_memory=True,\n",
    ")\n",
    "val_data_loader = DataLoader(\n",
    "    val_dataset, batch_size=params[\"batch_size\"], shuffle=False, num_workers=params[\"num_workers\"], pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HNz-5F7Bh5_Y"
   },
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch, params):\n",
    "    metric_monitor = MetricMonitor()\n",
    "    model.train()\n",
    "    stream = tqdm(train_loader)\n",
    "    for i, (images, target) in enumerate(stream, start=1):\n",
    "        images = images.to(params[\"device\"], non_blocking=True)\n",
    "        target = target.to(params[\"device\"], non_blocking=True).long()\n",
    "        output = model(images)\n",
    "        loss = criterion(output, target)\n",
    "        accuracy = calculate_accuracy(output, target)\n",
    "        metric_monitor.update(\"Loss\", loss.item())\n",
    "        metric_monitor.update(\"Accuracy\", accuracy)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        stream.set_description(\n",
    "            \"Epoch: {epoch}. Train. {metric_monitor}\".format(epoch=epoch, metric_monitor=metric_monitor)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "chKMqryvh5_a"
   },
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion, epoch, params):\n",
    "    metric_monitor = MetricMonitor()\n",
    "    model.eval()\n",
    "    stream = tqdm(val_loader)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (images, target) in enumerate(stream, start=1):\n",
    "            images = images.to(params[\"device\"], non_blocking=True)\n",
    "            target = target.to(params[\"device\"], non_blocking=True).long()\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "            accuracy = calculate_accuracy(output, target)\n",
    "\n",
    "            metric_monitor.update(\"Loss\", loss.item())\n",
    "            metric_monitor.update(\"Accuracy\", accuracy)\n",
    "            stream.set_description(\n",
    "                \"Epoch: {epoch}. Validation. {metric_monitor}\".format(epoch=epoch, metric_monitor=metric_monitor)\n",
    "            )\n",
    "            \n",
    "    Logger.current_logger().report_scalar(\n",
    "        \"val\", \"loss\", iteration=epoch, value=metric_monitor.metrics['Loss']['val'])\n",
    "    Logger.current_logger().report_scalar(\n",
    "        \"val\", \"accuracy\", iteration=epoch, value=metric_monitor.metrics['Accuracy']['val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "IiA5Zgfch5_c",
    "outputId": "f4fba281-0997-4202-e9d2-6aa3f93373f0",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for epoch in range(1, params[\"epochs\"] + 1):\n",
    "    train(train_data_loader, model, criterion, optimizer, epoch, params)\n",
    "    asd = validate(val_data_loader, model, criterion, epoch, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folder = 'model/'\n",
    "os.makedirs(model_folder)\n",
    "torch.save(model.state_dict(), os.path.join(model_folder, 'resnet18.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task.mark_completed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "classification (1) (1).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
